# -*- coding: utf-8 -*-
"""stray_dog.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ydXM8suvDfmOTBNhxNqNFYEpLVdIvGSt
"""

# Install kagglehub if not installed
!pip install kagglehub

# Import required libraries
import kagglehub
import os

# Download dataset using kagglehub
dataset_path = kagglehub.dataset_download("youssefmohmmed/dogs-skin-diseases-image-dataset")

# The dataset is already extracted, so define the correct paths
train_dir = os.path.join(dataset_path, "train")
valid_dir = os.path.join(dataset_path, "valid")
test_dir = os.path.join(dataset_path, "test")

print("Dataset is ready!")
print(f"Train Data Path: {train_dir}")
print(f"Validation Data Path: {valid_dir}")
print(f"Test Data Path: {test_dir}")

import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.models import load_model
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

"""data preprocessing"""

# Define Image Size and Batch Size
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

# Data Augmentation & Normalization
datagen = ImageDataGenerator(rescale=1./255,
                             rotation_range=20,
                             zoom_range=0.2,
                             horizontal_flip=True)

# Load Train, Validation, and Test Data
train_data = datagen.flow_from_directory(train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical")
valid_data = datagen.flow_from_directory(valid_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical")
test_data = datagen.flow_from_directory(test_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="categorical", shuffle=False)

# Print class labels
class_names = list(train_data.class_indices.keys())
print("Class Labels:", class_names)

# Load Pretrained MobileNetV2 Model
base_model = MobileNetV2(weights="imagenet", include_top=False, input_shape=(224, 224, 3))

# Freeze base model layers
for layer in base_model.layers:
    layer.trainable = False

# Add Custom Layers
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation="relu")(x)
x = Dropout(0.5)(x)
output_layer = Dense(len(class_names), activation="softmax")(x)

# Define Final Model
model = Model(inputs=base_model.input, outputs=output_layer)

# Compile Model
model.compile(optimizer=Adam(learning_rate=0.0001), loss="categorical_crossentropy", metrics=["accuracy"])

# Model Summary
model.summary()

# Early Stopping to prevent overfitting
early_stopping = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)

# Train the Model
history = model.fit(train_data, validation_data=valid_data, epochs=20, callbacks=[early_stopping])

# Plot Training Performance
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label="Train Accuracy")
plt.plot(history.history['val_accuracy'], label="Validation Accuracy")
plt.legend()
plt.title("Accuracy Curve")

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label="Train Loss")
plt.plot(history.history['val_loss'], label="Validation Loss")
plt.legend()
plt.title("Loss Curve")

plt.show()

# Predict on Test Data
y_pred = model.predict(test_data)
y_pred_classes = np.argmax(y_pred, axis=1)

# True Labels
y_true = test_data.classes

# Classification Report
print(classification_report(y_true, y_pred_classes, target_names=class_names))

# Confusion Matrix
conf_matrix = confusion_matrix(y_true, y_pred_classes)

plt.figure(figsize=(8,6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# Save Model
model.save("dog_skin_disease_model.h5")
print("Model saved!")

# Load Model
loaded_model = load_model("dog_skin_disease_model.h5")
print("Model loaded successfully!")

from tensorflow.keras.preprocessing import image

import tensorflow as tf
import numpy as np
import cv2
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image  # âœ… Import fixed

# Load your trained model
model = tf.keras.models.load_model("/content/dog_skin_disease_model.h5")

# Load test image
img_path = "/content/test2_healthy.jpg"  # Update with correct path
img = image.load_img(img_path, target_size=(224, 224))  # Resize to model input

# Convert image to array
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Expand dims for batch processing
img_array = img_array / 255.0  # Normalize pixel values

# Make prediction
predictions = model.predict(img_array)
predicted_class = np.argmax(predictions)  # Get class index

# Define class labels (based on your dataset)
class_labels = ["Dermatitis", "Fungal Infections", "Healthy", "Hypersensitivity", "Demodicosis", "Ringworm"]
predicted_label = class_labels[predicted_class]

# Display result
plt.imshow(cv2.imread(img_path)[:, :, ::-1])  # Convert BGR to RGB
plt.axis("off")
plt.title(f"Predicted: {predicted_label}")
plt.show()